{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting Ensemble basados ​​en histogramas:**\n",
        "\n",
        "https://machinelearningmastery.com/histogram-based-gradient-boosting-ensembles/\n",
        "\n",
        "El aumento de gradiente es un conjunto de algoritmos de árboles de decisión.\n",
        "\n",
        "Puede ser una de las técnicas más populares para la clasificación estructurada (tabular) y los problemas de modelado predictivo de regresión dado que funciona muy bien en una amplia gama de conjuntos de datos en la práctica.\n",
        "\n",
        "Un problema importante del aumento de gradiente es que es lento para entrenar el modelo. Esto es particularmente un problema cuando se usa el modelo en grandes conjuntos de datos con decenas de miles de ejemplos (filas).\n",
        "\n",
        "El entrenamiento de los árboles que se agregan al conjunto se puede acelerar drásticamente al discretizar (agrupar) las variables de entrada continuas en unos pocos cientos de valores únicos. Los conjuntos de aumento de gradiente que implementan esta técnica y adaptan el algoritmo de entrenamiento en torno a las variables de entrada bajo esta transformación se denominan conjuntos de aumento de gradiente basados ​​en histogramas.\n",
        "\n",
        "Aprenderemos lo siguiente:\n",
        "\n",
        "Gradient boosting basada en histogramas es una técnica para entrenar árboles de decisión más rápidos que se utilizan en el ensemble de gradient boosting.\n",
        "\n",
        "Cómo usar la implementación experimental del gradient  boosting basado en histogramas en la biblioteca scikit-learn.\n",
        "\n",
        "Cómo usar Gradient Boosting Ensembles basados ​​en histogramas con las bibliotecas de terceros XGBoost y LightGBM."
      ],
      "metadata": {
        "id": "bpdFweKJJ1eF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2CHx7JTJ0qh",
        "outputId": "9edd822d-395e-4f0c-f354-74181f67a3dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# explicitly require this experimental feature\n",
        "from sklearn.experimental import enable_hist_gradient_boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La documentación de scikit-learn afirma que estas implementaciones de aumento de gradiente basadas en histogramas son órdenes de magnitud más rápidas que la implementación de aumento de gradiente predeterminada proporcionada por la biblioteca.\n",
        "\n",
        "HistGradientBoostingClassifier es una implementación de Gradient Boosting optimizada para conjuntos de datos grandes. La diferencia clave entre este clasificador y otros métodos de Gradient Boosting radica en cómo maneja los histogramas para mejorar la eficiencia computacional.\n",
        "\n",
        "Estos estimadores basados ​​en histogramas pueden ser mucho más rápidos que GradientBoostingClassifier y GradientBoostingRegressor cuando el número de muestras es mayor que decenas de miles de muestras.\n",
        "\n",
        "Las clases se pueden usar como cualquier otro modelo de scikit-learn.\n",
        "\n",
        "De forma predeterminada, el conjunto utiliza 255 bins para cada función de entrada continua, y esto se puede configurar a través del argumento \"max_bins\". Establecer esto en valores más pequeños, como 50 o 100, puede dar como resultado más mejoras en la eficiencia, aunque quizás a costa de algunas habilidades del modelo.\n",
        "\n",
        "El número de árboles se puede establecer a través del argumento \"max_iter\" y el valor predeterminado es 100.\n",
        "\n",
        "Cuando se entrena un modelo de Gradient Boosting, en cada iteración se ajusta un árbol débil para corregir los errores del modelo existente. Tradicionalmente, se construyen árboles considerando todas las características y calculando las divisiones óptimas para cada característica. Sin embargo, este enfoque puede ser computacionalmente costoso, especialmente en conjuntos de datos grandes.\n",
        "\n",
        "La versión \"histogram-based\" de Gradient Boosting, como la implementada en HistGradientBoostingClassifier, utiliza histogramas para reducir la complejidad computacional. En lugar de considerar todas las características y calcular divisiones precisas, este método agrupa los valores de las características en histogramas discretos. Luego, durante la construcción del árbol, se toman decisiones basadas en estos histogramas en lugar de realizar cálculos intensivos."
      ],
      "metadata": {
        "id": "IbMX7NghL5kE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate sklearn histogram gradient boosting algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=100, n_informative=50, n_redundant=50, random_state=1)\n",
        "# define the model\n",
        "model = HistGradientBoostingClassifier(max_bins=255, max_iter=100)\n",
        "# define the evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t35gwmDUL6k3",
        "outputId": "2057871c-a0dc-4503-df95-c67467f63ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.943 (0.007)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutar el ejemplo evalúa el rendimiento del modelo en el conjunto de datos sintéticos e informa la precisión de la clasificación de la media y la desviación estándar.\n",
        "\n",
        "Nota: Nuestros resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o las diferencias en la precisión numérica. Consideremos ejecutar el ejemplo varias veces y comparenos el resultado promedio.\n",
        "\n",
        "En este caso, podemos ver que el algoritmo de aumento de gradiente de histograma de scikit-learn logra una precisión media de alrededor del 94,3 por ciento en el conjunto de datos sintéticos.\n",
        "\n",
        "También podemos explorar el efecto del número de bins en el rendimiento del modelo.\n",
        "\n",
        "El siguiente ejemplo evalúa el rendimiento del modelo con un número diferente de bins para cada característica de entrada continua de 50 a (aproximadamente) 250 en incrementos de 50.\n",
        "\n",
        "El ejemplo completo se muestra a continuación."
      ],
      "metadata": {
        "id": "CnYTJyr2McaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compare number of bins for sklearn histogram gradient boosting\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=10000, n_features=100, n_informative=50, n_redundant=50, random_state=1)\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\tfor i in [10, 50, 100, 150, 200, 255]:\n",
        "\t\tmodels[str(i)] = HistGradientBoostingClassifier(max_bins=i, max_iter=100)\n",
        "\treturn models\n",
        "\n",
        "# evaluate a give model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\t# define the evaluation procedure\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\t# evaluate the model and collect the scores\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\t# evaluate the model and collect the scores\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\t# stores the results\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\t# report performance along the way\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "vgRvvBErMkHP",
        "outputId": "e787b834-f43a-4213-c3ff-4f077cbb386f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">10 0.945 (0.009)\n",
            ">50 0.944 (0.007)\n",
            ">100 0.944 (0.008)\n",
            ">150 0.944 (0.008)\n",
            ">200 0.944 (0.007)\n",
            ">255 0.943 (0.007)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al ejecutar el ejemplo, se evalúa cada configuración, se informa la precisión de clasificación de la media y la desviación estándar a lo largo del camino y, finalmente, se crea un gráfico de la distribución de puntuaciones.\n",
        "\n",
        "Nota: Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o las diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y compare el resultado promedio.\n",
        "\n",
        "En este caso, podemos ver que aumentar la cantidad de bins puede disminuir la precisión media del modelo en este conjunto de datos.\n",
        "\n",
        "Podríamos esperar que un aumento en la cantidad de bins también requiera un aumento en la cantidad de árboles (max_iter) para garantizar que el modelo pueda explorar y aprovechar de manera efectiva los puntos de división adicionales.\n",
        "\n",
        "Es importante destacar que ajustar un conjunto donde los árboles usan 10 o 50 bins por variable es mucho más rápido que 255 bins por variable de entrada.\n",
        "\n",
        ">10 0,945 (0,009)\n",
        ">50 0,944 (0,007)\n",
        ">100 0,944 (0,008)\n",
        ">150 0,944 (0,008)\n",
        ">200 0,944 (0,007)\n",
        ">255 0,943 (0,007)\n",
        "Se crea una figura que compara la distribución de las puntuaciones de precisión para cada configuración mediante diagramas de caja y bigotes.\n",
        "\n",
        "En este caso, podemos ver que aumentar el número de bins en el histograma parece reducir la dispersión de la distribución, aunque puede disminuir el rendimiento medio del modelo."
      ],
      "metadata": {
        "id": "0Hl3eRqIMqeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting de histograma con XGBoost:**\n",
        "\n",
        "Extreme Gradient Boosting, o XGBoost para abreviar, es una biblioteca que proporciona una implementación altamente optimizada de aumento de gradiente.\n",
        "\n",
        "Una de las técnicas implementadas en la biblioteca es el uso de histogramas para las variables de entrada continuas.\n",
        "\n",
        "La biblioteca XGBoost se puede instalar usando su administrador de paquetes de Python favorito, como Pip;\n",
        "\n",
        "Podemos desarrollar modelos XGBoost para usar con la biblioteca scikit-learn a través de las clases XGBClassifier y XGBRegressor.\n",
        "\n",
        "El algoritmo de entrenamiento se puede configurar para usar el método de histograma configurando el argumento \"tree_method\" en 'aprox', y la cantidad de bins se puede configurar a través del argumento \"max_bin\".\n",
        "\n",
        "modelo = XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100)\n",
        "\n",
        "El siguiente ejemplo demuestra la evaluación de un modelo XGBoost configurado para usar el histograma o la técnica aproximada para construir árboles con 255 bins por entidad de entrada continua y 100 árboles en el modelo."
      ],
      "metadata": {
        "id": "es6gYnfiM1j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwKSDROiNDmy",
        "outputId": "2e5c8379-5005-4ea2-cb00-35029fec2568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate xgboost histogram gradient boosting algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from xgboost import XGBClassifier\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=100, n_informative=50, n_redundant=50, random_state=1)\n",
        "# define the model\n",
        "model = XGBClassifier(tree_method='approx', max_bin=255, n_estimators=100)\n",
        "# define the evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3rtQun8M0IN",
        "outputId": "f7f2e7b7-b206-4111-dc4e-94b4c5b9a891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956 (0.007)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutar el ejemplo evalúa el rendimiento del modelo en el conjunto de datos sintéticos e informa la precisión de la clasificación de la media y la desviación estándar.\n",
        "\n",
        "**Nota:** Sus resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o las diferencias en la precisión numérica. Considere ejecutar el ejemplo varias veces y compare el resultado promedio.\n",
        "\n",
        "En este caso, podemos ver que el algoritmo de aumento de gradiente de histograma XGBoost logra una precisión media de alrededor del 95,7 por ciento en el conjunto de datos sintético.\n",
        "\n",
        "Precisión: 0,957 (0,007)\n",
        "\n",
        "**Gradient Boosting de histograma con LightGBM:**\n",
        "\n",
        "Light Gradient Boosting Machine o LightGBM para abreviar es otra biblioteca de terceros como XGBoost que proporciona una implementación altamente optimizada de aumento de gradiente.\n",
        "\n",
        "Es posible que haya implementado la técnica de histograma antes de XGBoost, pero XGBoost implementó más tarde la misma técnica, destacando la competencia de \"eficiencia de aumento de gradiente\" entre las bibliotecas de aumento de gradiente.\n",
        "\n",
        "La biblioteca LightGBM se puede instalar utilizando su administrador de paquetes favorito de Python, como Pip; Por ejemplo:"
      ],
      "metadata": {
        "id": "ZKl2U_A_NXlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPEdg6klNf2H",
        "outputId": "abe1d142-5797-49d7-feaf-3fcc0fba6201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos desarrollar modelos LightGBM para usar con la biblioteca scikit-learn a través de las clases LGBMClassifier y LGBMRegressor.\n",
        "\n",
        "El algoritmo de entrenamiento usa histogramas por defecto. Los bins máximos por variable de entrada continua se pueden establecer a través del argumento \"max_bin\".\n",
        "\n",
        "modelo = LGBMClassifier(max_bin=255, n_estimators=100)\n",
        "\n",
        "El siguiente ejemplo demuestra la evaluación de un modelo LightGBM configurado para usar el histograma o la técnica aproximada para construir árboles con 255 bins por entidad de entrada continua y 100 árboles en el modelo."
      ],
      "metadata": {
        "id": "tK7pf9KMNozo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate lightgbm histogram gradient boosting algorithm for classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from lightgbm import LGBMClassifier\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=100, n_informative=50, n_redundant=50, random_state=1)\n",
        "# define the model\n",
        "model = LGBMClassifier(max_bin=255, n_estimators=100)\n",
        "# define the evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHKxFvkoNtRb",
        "outputId": "e3542000-fb0b-45df-8c5c-656c1315c387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.943 (0.008)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutar el ejemplo evalúa el rendimiento del modelo en el conjunto de datos sintéticos e informa la precisión de la clasificación de la media y la desviación estándar.\n",
        "\n",
        "**Nota:** Nuestos resultados pueden variar dada la naturaleza estocástica del algoritmo o procedimiento de evaluación, o las diferencias en la precisión numérica. Consideremos ejecutar el ejemplo varias veces y comparemos el resultado promedio.\n",
        "\n",
        "En este caso, podemos ver que el algoritmo de aumento de gradiente de histograma LightGBM logra una precisión media de alrededor del 94,2 por ciento en el conjunto de datos sintéticos."
      ],
      "metadata": {
        "id": "q1OY0xk-Ny4O"
      }
    }
  ]
}